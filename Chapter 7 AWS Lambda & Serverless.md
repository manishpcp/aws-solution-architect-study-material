# Chapter 7: AWS Lambda \& Serverless

## Introduction

AWS Lambda revolutionized cloud computing by introducing serverless compute, eliminating the need to provision or manage servers. With Lambda, you upload your code, and AWS handles everything else: provisioning capacity, scaling, patching, monitoring, and high availability. This paradigm shift allows developers to focus entirely on business logic while AWS manages the infrastructure, embodying the true promise of cloud computing—paying only for what you use, measured in milliseconds.

Serverless architecture extends far beyond Lambda itself. Amazon API Gateway provides fully managed REST and WebSocket APIs, Amazon EventBridge enables event-driven architectures, AWS Step Functions orchestrates complex workflows, and DynamoDB offers serverless NoSQL databases. Together, these services form a complete serverless ecosystem where you can build sophisticated applications without managing a single server. This architecture pattern is particularly powerful for event-driven workloads, microservices, data processing pipelines, and backends for mobile and web applications.

However, serverless computing introduces unique challenges and paradigms. Cold starts impact response times when functions haven't been invoked recently. Concurrency limits can throttle applications during traffic spikes. VPC Lambda functions face initialization latency. Memory allocation directly affects both performance and cost. State management requires external services since Lambda functions are stateless. Understanding these nuances separates successful serverless implementations from problematic ones.

This chapter provides comprehensive coverage of AWS Lambda and serverless architectures from fundamentals to production patterns. You'll learn Lambda's execution model, event sources, deployment patterns, performance optimization, error handling, observability, and cost optimization. Whether you're building APIs, processing streams, automating workflows, or creating event-driven systems, mastering Lambda is essential for modern AWS architectures.

## Theory \& Concepts

### Serverless Computing Fundamentals

**What is Serverless?**

Serverless doesn't mean "no servers"—servers still exist, but you don't manage them. AWS provisions, scales, and maintains infrastructure automatically.

**Key Characteristics:**

1. **No Server Management:** AWS handles provisioning, patching, scaling
2. **Automatic Scaling:** Scales from zero to thousands of concurrent executions
3. **Pay-per-Use:** Charged only for compute time consumed (100ms increments)
4. **Event-Driven:** Triggered by events (HTTP requests, file uploads, database changes)
5. **Stateless:** Each invocation is independent; state stored externally
6. **Built-in Availability:** Automatically deployed across multiple AZs

**Benefits:**

- No infrastructure management
- Automatic scaling
- Cost-efficient for variable workloads
- Faster time to market
- Built-in high availability

**Trade-offs:**

- Cold start latency
- Execution time limits (15 minutes max)
- Vendor lock-in considerations
- Debugging complexity
- Limited control over runtime environment


### Lambda Execution Model

**Invocation Flow:**

```
Event Source → Lambda Service → Execution Environment → Your Code → Response
                     ↓
              [Cold Start if needed]
                     ↓
           Initialize runtime + code
                     ↓
              Reuse environment for warm invocations
```

**Execution Phases:**

**1. Init Phase (Cold Start):**

- Download function code
- Initialize runtime (Node.js, Python, Java, etc.)
- Execute initialization code (outside handler)
- ~100ms-1000ms+ depending on runtime and code size

**2. Invoke Phase:**

- Execute handler function
- Process event
- Return response
- ~1ms-15min (timeout configurable)

**3. Shutdown Phase:**

- Environment frozen after invocation
- May be reused for subsequent invocations (warm start)
- Eventually shut down after inactivity


### Cold Starts vs Warm Starts

**Cold Start:**
First invocation or after period of inactivity requiring environment initialization.

```
Timeline:
├─ 0ms: Event arrives
├─ 100ms: Initialize runtime
├─ 200ms: Load dependencies
├─ 300ms: Execute init code
├─ 350ms: START handler execution
└─ 450ms: Complete

Total: 450ms (100ms billed execution time)
```

**Warm Start:**
Subsequent invocation reusing existing execution environment.

```
Timeline:
├─ 0ms: Event arrives
├─ 5ms: START handler execution (reuses environment)
└─ 105ms: Complete

Total: 105ms (100ms billed execution time)
```

**Cold Start Duration by Runtime:**


| Runtime | Typical Cold Start | With Dependencies |
| :-- | :-- | :-- |
| Python 3.11 | 100-200ms | 200-500ms |
| Node.js 18 | 150-250ms | 250-600ms |
| Java 17 | 500-1000ms | 1000-3000ms |
| .NET 6 | 400-800ms | 800-2000ms |
| Go 1.x | 100-150ms | 150-300ms |
| Rust | 80-120ms | 120-250ms |

**Factors Affecting Cold Starts:**

1. **Runtime:** Compiled languages (Go, Rust) faster than JVM (Java, .NET)
2. **Memory Allocation:** More memory = more CPU = faster initialization
3. **Code Package Size:** Larger packages take longer to download/extract
4. **VPC Configuration:** VPC Lambdas have additional ENI setup time
5. **Dependencies:** More dependencies = longer initialization
6. **Lambda SnapStart:** Java functions start ~10x faster

### Lambda Configuration

**Memory \& CPU:**

Memory: 128 MB to 10,240 MB (10 GB) in 1 MB increments
CPU: Scales linearly with memory

- 128 MB = ~0.08 vCPU
- 1,769 MB = 1 full vCPU
- 10,240 MB = ~6 vCPU

**Timeout:**

- Default: 3 seconds
- Maximum: 900 seconds (15 minutes)
- Set based on expected execution time

**Ephemeral Storage (/tmp):**

- Default: 512 MB
- Maximum: 10,240 MB (10 GB)
- Shared across invocations in same execution environment

**Concurrency:**

- **Account Level:** 1,000 concurrent executions (default, soft limit)
- **Reserved:** Guarantee capacity for function
- **Provisioned:** Pre-initialized environments (no cold starts)

**Environment Variables:**

- Max 4 KB total size
- Encrypted at rest with KMS
- Use for configuration, not secrets (use Secrets Manager)


### Event Sources and Invocation Types

**Invocation Types:**

**1. Synchronous (Request-Response):**
Caller waits for response.

```python
# Client waits for Lambda to complete
import boto3
lambda_client = boto3.client('lambda')

response = lambda_client.invoke(
    FunctionName='my-function',
    InvocationType='RequestResponse',  # Synchronous
    Payload=json.dumps({'key': 'value'})
)

result = json.loads(response['Payload'].read())
```

**Use Cases:** API Gateway, ALB, SDK invoke

**2. Asynchronous (Fire-and-Forget):**
Caller doesn't wait; Lambda manages retries.

```python
# Client doesn't wait
response = lambda_client.invoke(
    FunctionName='my-function',
    InvocationType='Event',  # Asynchronous
    Payload=json.dumps({'key': 'value'})
)
# Returns immediately with 202 status
```

**Use Cases:** S3 events, SNS, EventBridge
**Retries:** Up to 2 automatic retries on error
**DLQ:** Failed events sent to SQS or SNS

**3. Poll-Based (Stream/Queue):**
Lambda polls event source.

**Use Cases:**

- Kinesis Data Streams
- DynamoDB Streams
- SQS (Standard and FIFO)
- Amazon MQ
- Kafka (MSK/Self-managed)

Lambda service polls source and invokes function with batches.

### Common Event Sources

| Event Source | Invocation Type | Batch Support | Use Case |
| :-- | :-- | :-- | :-- |
| **API Gateway** | Sync | No | REST APIs |
| **ALB** | Sync | No | HTTP endpoints |
| **S3** | Async | Yes | File processing |
| **SNS** | Async | No | Pub/sub notifications |
| **SQS** | Poll | Yes | Queue processing |
| **EventBridge** | Async | No | Scheduled tasks, events |
| **DynamoDB Streams** | Poll | Yes | Database triggers |
| **Kinesis** | Poll | Yes | Stream processing |
| **CloudWatch Logs** | Async | No | Log processing |
| **Cognito** | Sync | No | Auth triggers |
| **Step Functions** | Sync | No | Workflow tasks |

### Lambda Pricing

**Compute Charges:**

```
Price per request: $0.20 per 1M requests
Price per GB-second: $0.0000166667 per GB-second

Example 1: 128 MB, 100ms duration, 1M invocations/month
- Request cost: 1M × $0.20 / 1M = $0.20
- Compute cost: 1M × 0.125 GB × 0.1 sec × $0.0000166667 = $0.21
- Total: $0.41/month

Example 2: 1024 MB (1 GB), 500ms duration, 5M invocations/month
- Request cost: 5M × $0.20 / 1M = $1.00
- Compute cost: 5M × 1 GB × 0.5 sec × $0.0000166667 = $41.67
- Total: $42.67/month
```

**Free Tier (Monthly, Always Free):**

- 1M requests
- 400,000 GB-seconds compute time

**Provisioned Concurrency Additional Charges:**

- \$0.000004167 per GB-second
- \$0.015 per GB-hour

**Example Provisioned Concurrency:**

```
10 functions with 1 GB memory, provisioned 24/7
Cost: 10 × 1 GB × 730 hours × $0.015 = $109.50/month
(Plus regular invocation charges)
```


### Lambda Permissions

**Execution Role:**
IAM role Lambda assumes to access AWS services.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::my-bucket/*"
    }
  ]
}
```

**Resource-Based Policy:**
Controls who can invoke the function.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "s3.amazonaws.com"
      },
      "Action": "lambda:InvokeFunction",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:my-function",
      "Condition": {
        "StringEquals": {
          "AWS:SourceAccount": "123456789012"
        }
      }
    }
  ]
}
```


### Lambda Layers

Layers allow sharing code/dependencies across functions.

**Structure:**

```
layer.zip
└── python/  (or nodejs/, java/lib/, etc.)
    └── shared_library.py
```

**Benefits:**

- Reduce deployment package size
- Share common code across functions
- Separate business logic from dependencies
- Faster deployments

**Limitations:**

- Max 5 layers per function
- Total unzipped size (function + layers) ≤ 250 MB
- Layer versions are immutable

**Use Cases:**

- Shared libraries (AWS SDK, data processing)
- Common utilities
- Large dependencies (ML models)


### Concurrency and Throttling

**Concurrency Types:**

**1. Account Concurrency Limit:**

- Default: 1,000 per region
- Soft limit: Can request increase
- Shared across all functions in account/region

**2. Reserved Concurrency:**

- Guarantees capacity for function
- Reduces account pool for other functions
- Prevents function from consuming all capacity

```bash
aws lambda put-function-concurrency \
    --function-name my-function \
    --reserved-concurrent-executions 100
```

**3. Provisioned Concurrency:**

- Pre-initialized execution environments
- No cold starts
- Pays extra for warm instances
- Use for latency-sensitive workloads

```bash
aws lambda put-provisioned-concurrency-config \
    --function-name my-function \
    --provisioned-concurrent-executions 50 \
    --qualifier prod
```

**Throttling:**

When concurrency limit exceeded:

- **Synchronous:** Returns 429 (TooManyRequestsException)
- **Asynchronous:** Retries automatically, then DLQ
- **Stream-based:** Lambda retries until success or data expires

**Concurrency Formula:**

```
Concurrency = (Invocations per second) × (Average duration in seconds)

Example:
100 requests/sec × 2 sec duration = 200 concurrent executions needed
```


### VPC Lambda Configuration

Lambda functions can access resources in VPC (RDS, ElastiCache, etc.).

**Traditional VPC Lambda (Pre-2019):**

- Created ENI per subnet
- Slow cold starts (10-60 seconds)
- ENI creation bottleneck

**Hyperplane ENI (Current):**

- Shared ENI pool across functions
- Fast cold starts (~1 second additional latency)
- Scales much better

**Configuration:**

```json
{
  "VpcConfig": {
    "SubnetIds": ["subnet-1", "subnet-2"],
    "SecurityGroupIds": ["sg-1"]
  }
}
```

**Recommendations:**

- Use private subnets
- NAT Gateway for internet access
- VPC endpoints for AWS services (avoid NAT charges)
- Place Lambda and resources in same AZ when possible


### Lambda SnapStart (Java)

SnapStart dramatically reduces cold starts for Java functions.

**How It Works:**

1. Lambda initializes function
2. Takes snapshot of initialized state
3. Caches snapshot
4. Restores from snapshot on cold start (instead of re-initializing)

**Performance:**

- 10x faster cold starts
- From 2-3 seconds → 200-300ms

**Limitations:**

- Java 11+ only
- No support for: /tmp writes, networking during init
- Unique state must be generated per invocation

**Use Cases:**

- Spring Boot applications
- Java microservices
- Applications with slow initialization


## Hands-On Implementation

### Lab 1: Building Your First Lambda Function

**Objective:** Create a Lambda function that processes S3 events.

#### Step 1: Create Lambda Function (Python)

```python
# lambda_function.py
import json
import boto3
import urllib.parse

s3 = boto3.client('s3')

def lambda_handler(event, context):
    """
    Process S3 object uploads
    - Get object metadata
    - Log object details
    - Return success response
    """
    
    print(f"Received event: {json.dumps(event)}")
    
    # Get bucket and key from event
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])
    
    try:
        # Get object metadata
        response = s3.head_object(Bucket=bucket, Key=key)
        
        metadata = {
            'bucket': bucket,
            'key': key,
            'size': response['ContentLength'],
            'content_type': response.get('ContentType', 'unknown'),
            'last_modified': response['LastModified'].isoformat()
        }
        
        print(f"Object metadata: {json.dumps(metadata)}")
        
        # Process object (example: get first 1000 bytes)
        obj = s3.get_object(Bucket=bucket, Key=key)
        content = obj['Body'].read(1000).decode('utf-8', errors='ignore')
        
        print(f"Content preview: {content[:100]}...")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Successfully processed object',
                'metadata': metadata
            })
        }
        
    except Exception as e:
        print(f"Error processing object: {str(e)}")
        raise e
```


#### Step 2: Create IAM Role

```bash
# Create trust policy
cat > lambda-trust-policy.json <<'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF

# Create role
ROLE_ARN=$(aws iam create-role \
    --role-name S3ProcessorLambdaRole \
    --assume-role-policy-document file://lambda-trust-policy.json \
    --query 'Role.Arn' \
    --output text)

# Attach basic execution policy
aws iam attach-role-policy \
    --role-name S3ProcessorLambdaRole \
    --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

# Create custom policy for S3 access
cat > s3-policy.json <<'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:HeadObject"
      ],
      "Resource": "arn:aws:s3:::my-upload-bucket/*"
    }
  ]
}
EOF

aws iam put-role-policy \
    --role-name S3ProcessorLambdaRole \
    --policy-name S3AccessPolicy \
    --policy-document file://s3-policy.json
```


#### Step 3: Deploy Lambda Function

```bash
# Package function
zip function.zip lambda_function.py

# Create function
FUNCTION_ARN=$(aws lambda create-function \
    --function-name s3-object-processor \
    --runtime python3.11 \
    --role $ROLE_ARN \
    --handler lambda_function.lambda_handler \
    --zip-file fileb://function.zip \
    --timeout 30 \
    --memory-size 256 \
    --environment Variables="{LOG_LEVEL=INFO}" \
    --tags Environment=Production,Application=DataProcessing \
    --query 'FunctionArn' \
    --output text)

echo "Function ARN: $FUNCTION_ARN"
```


#### Step 4: Configure S3 Trigger

```bash
# Add permission for S3 to invoke Lambda
aws lambda add-permission \
    --function-name s3-object-processor \
    --statement-id s3-invoke-permission \
    --action lambda:InvokeFunction \
    --principal s3.amazonaws.com \
    --source-arn arn:aws:s3:::my-upload-bucket

# Configure S3 event notification
cat > s3-notification.json <<'EOF'
{
  "LambdaFunctionConfigurations": [
    {
      "LambdaFunctionArn": "'$FUNCTION_ARN'",
      "Events": ["s3:ObjectCreated:*"],
      "Filter": {
        "Key": {
          "FilterRules": [
            {
              "Name": "prefix",
              "Value": "uploads/"
            },
            {
              "Name": "suffix",
              "Value": ".json"
            }
          ]
        }
      }
    }
  ]
}
EOF

aws s3api put-bucket-notification-configuration \
    --bucket my-upload-bucket \
    --notification-configuration file://s3-notification.json
```


#### Step 5: Test Function

```bash
# Upload test file
echo '{"test": "data"}' > test.json
aws s3 cp test.json s3://my-upload-bucket/uploads/test.json

# Check CloudWatch Logs
aws logs tail /aws/lambda/s3-object-processor --follow
```


### Lab 2: Building REST API with Lambda and API Gateway

**Objective:** Create a serverless REST API for managing todo items.

#### Step 1: Create DynamoDB Table

```bash
aws dynamodb create-table \
    --table-name TodoItems \
    --attribute-definitions \
        AttributeName=userId,AttributeType=S \
        AttributeName=todoId,AttributeType=S \
    --key-schema \
        AttributeName=userId,KeyType=HASH \
        AttributeName=todoId,KeyType=RANGE \
    --billing-mode PAY_PER_REQUEST \
    --tags Key=Environment,Value=Production
```


#### Step 2: Create Lambda Functions

```python
# todo_api.py
import json
import boto3
import uuid
from datetime import datetime

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('TodoItems')

def lambda_handler(event, context):
    """
    Handle CRUD operations for todo items
    """
    
    http_method = event['httpMethod']
    path = event['path']
    
    # Extract user ID from request context (assumes API Gateway authorizer)
    user_id = event['requestContext']['authorizer']['claims']['sub']
    
    try:
        if http_method == 'GET' and path == '/todos':
            return get_todos(user_id)
        
        elif http_method == 'GET' and '/todos/' in path:
            todo_id = path.split('/')[-1]
            return get_todo(user_id, todo_id)
        
        elif http_method == 'POST' and path == '/todos':
            body = json.loads(event['body'])
            return create_todo(user_id, body)
        
        elif http_method == 'PUT' and '/todos/' in path:
            todo_id = path.split('/')[-1]
            body = json.loads(event['body'])
            return update_todo(user_id, todo_id, body)
        
        elif http_method == 'DELETE' and '/todos/' in path:
            todo_id = path.split('/')[-1]
            return delete_todo(user_id, todo_id)
        
        else:
            return response(404, {'error': 'Not found'})
    
    except Exception as e:
        print(f"Error: {str(e)}")
        return response(500, {'error': 'Internal server error'})

def get_todos(user_id):
    """Get all todos for user"""
    result = table.query(
        KeyConditionExpression='userId = :userId',
        ExpressionAttributeValues={':userId': user_id}
    )
    return response(200, result['Items'])

def get_todo(user_id, todo_id):
    """Get specific todo"""
    result = table.get_item(
        Key={'userId': user_id, 'todoId': todo_id}
    )
    
    if 'Item' not in result:
        return response(404, {'error': 'Todo not found'})
    
    return response(200, result['Item'])

def create_todo(user_id, body):
    """Create new todo"""
    todo_id = str(uuid.uuid4())
    timestamp = datetime.utcnow().isoformat()
    
    item = {
        'userId': user_id,
        'todoId': todo_id,
        'title': body['title'],
        'completed': False,
        'createdAt': timestamp,
        'updatedAt': timestamp
    }
    
    table.put_item(Item=item)
    return response(201, item)

def update_todo(user_id, todo_id, body):
    """Update existing todo"""
    timestamp = datetime.utcnow().isoformat()
    
    result = table.update_item(
        Key={'userId': user_id, 'todoId': todo_id},
        UpdateExpression='SET title = :title, completed = :completed, updatedAt = :updatedAt',
        ExpressionAttributeValues={
            ':title': body.get('title'),
            ':completed': body.get('completed', False),
            ':updatedAt': timestamp
        },
        ReturnValues='ALL_NEW'
    )
    
    return response(200, result['Attributes'])

def delete_todo(user_id, todo_id):
    """Delete todo"""
    table.delete_item(
        Key={'userId': user_id, 'todoId': todo_id}
    )
    return response(204, {})

def response(status_code, body):
    """Format API Gateway response"""
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type,Authorization',
            'Access-Control-Allow-Methods': 'GET,POST,PUT,DELETE,OPTIONS'
        },
        'body': json.dumps(body)
    }
```


#### Step 3: Deploy Lambda with Dependencies

```bash
# Create requirements.txt
cat > requirements.txt <<'EOF'
boto3==1.28.0
EOF

# Install dependencies
pip install -r requirements.txt -t package/

# Copy function code
cp todo_api.py package/

# Create deployment package
cd package
zip -r ../function.zip .
cd ..

# Create Lambda function
aws lambda create-function \
    --function-name todo-api \
    --runtime python3.11 \
    --role $LAMBDA_ROLE_ARN \
    --handler todo_api.lambda_handler \
    --zip-file fileb://function.zip \
    --timeout 10 \
    --memory-size 512 \
    --environment Variables="{TABLE_NAME=TodoItems}"
```


#### Step 4: Create API Gateway

```bash
# Create REST API
API_ID=$(aws apigateway create-rest-api \
    --name "Todo API" \
    --description "Serverless Todo API" \
    --endpoint-configuration types=REGIONAL \
    --query 'id' \
    --output text)

# Get root resource ID
ROOT_ID=$(aws apigateway get-resources \
    --rest-api-id $API_ID \
    --query 'items[0].id' \
    --output text)

# Create /todos resource
TODOS_RESOURCE=$(aws apigateway create-resource \
    --rest-api-id $API_ID \
    --parent-id $ROOT_ID \
    --path-part todos \
    --query 'id' \
    --output text)

# Create GET method
aws apigateway put-method \
    --rest-api-id $API_ID \
    --resource-id $TODOS_RESOURCE \
    --http-method GET \
    --authorization-type NONE

# Integrate with Lambda
aws apigateway put-integration \
    --rest-api-id $API_ID \
    --resource-id $TODOS_RESOURCE \
    --http-method GET \
    --type AWS_PROXY \
    --integration-http-method POST \
    --uri arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/arn:aws:lambda:us-east-1:123456789012:function:todo-api/invocations

# Grant API Gateway permission to invoke Lambda
aws lambda add-permission \
    --function-name todo-api \
    --statement-id apigateway-invoke \
    --action lambda:InvokeFunction \
    --principal apigateway.amazonaws.com \
    --source-arn "arn:aws:execute-api:us-east-1:123456789012:$API_ID/*/*"

# Deploy API
aws apigateway create-deployment \
    --rest-api-id $API_ID \
    --stage-name prod

# Get API endpoint
echo "API Endpoint: https://$API_ID.execute-api.us-east-1.amazonaws.com/prod/todos"
```


### Lab 3: EventBridge Scheduled Lambda

**Objective:** Create scheduled Lambda function to clean up old data.

```python
# cleanup_lambda.py
import boto3
from datetime import datetime, timedelta

dynamodb = boto3.resource('dynamodb')
s3 = boto3.client('s3')
sns = boto3.client('sns')

def lambda_handler(event, context):
    """
    Daily cleanup job:
    - Delete old DynamoDB records
    - Remove old S3 objects
    - Send summary notification
    """
    
    results = {
        'dynamodb_deleted': 0,
        's3_deleted': 0,
        'errors': []
    }
    
    try:
        # Clean up DynamoDB (delete items older than 90 days)
        results['dynamodb_deleted'] = cleanup_dynamodb()
        
        # Clean up S3 (delete objects older than 30 days)
        results['s3_deleted'] = cleanup_s3()
        
        # Send success notification
        send_notification('success', results)
        
    except Exception as e:
        results['errors'].append(str(e))
        send_notification('error', results)
        raise
    
    return results

def cleanup_dynamodb():
    """Delete old DynamoDB items"""
    table = dynamodb.Table('TodoItems')
    cutoff_date = (datetime.now() - timedelta(days=90)).isoformat()
    
    # Scan for old items
    response = table.scan(
        FilterExpression='createdAt < :cutoff',
        ExpressionAttributeValues={':cutoff': cutoff_date}
    )
    
    deleted_count = 0
    for item in response['Items']:
        table.delete_item(
            Key={
                'userId': item['userId'],
                'todoId': item['todoId']
            }
        )
        deleted_count += 1
    
    return deleted_count

def cleanup_s3():
    """Delete old S3 objects"""
    bucket = 'my-temp-bucket'
    cutoff_date = datetime.now() - timedelta(days=30)
    
    paginator = s3.get_paginator('list_objects_v2')
    deleted_count = 0
    
    for page in paginator.paginate(Bucket=bucket, Prefix='temp/'):
        if 'Contents' not in page:
            continue
        
        for obj in page['Contents']:
            if obj['LastModified'].replace(tzinfo=None) < cutoff_date:
                s3.delete_object(Bucket=bucket, Key=obj['Key'])
                deleted_count += 1
    
    return deleted_count

def send_notification(status, results):
    """Send SNS notification"""
    topic_arn = 'arn:aws:sns:us-east-1:123456789012:cleanup-notifications'
    
    message = f"""
    Cleanup Job {status.upper()}
    
    Results:
    - DynamoDB items deleted: {results['dynamodb_deleted']}
    - S3 objects deleted: {results['s3_deleted']}
    - Errors: {len(results['errors'])}
    
    {json.dumps(results, indent=2)}
    """
    
    sns.publish(
        TopicArn=topic_arn,
        Subject=f'Cleanup Job {status.upper()}',
        Message=message
    )
```

**Create EventBridge Rule:**

```bash
# Create rule for daily execution
aws events put-rule \
    --name daily-cleanup \
    --description "Run cleanup Lambda daily at 2 AM UTC" \
    --schedule-expression "cron(0 2 * * ? *)" \
    --state ENABLED

# Add Lambda as target
aws events put-targets \
    --rule daily-cleanup \
    --targets "Id"="1","Arn"="arn:aws:lambda:us-east-1:123456789012:function:cleanup-lambda"

# Grant EventBridge permission
aws lambda add-permission \
    --function-name cleanup-lambda \
    --statement-id eventbridge-invoke \
    --action lambda:InvokeFunction \
    --principal events.amazonaws.com \
    --source-arn arn:aws:events:us-east-1:123456789012:rule/daily-cleanup
```

## Production-Level Knowledge

### Error Handling and Retry Logic

**Built-in Retry Behavior:**


| Invocation Type | Retries | Retry Interval | DLQ Support |
| :-- | :-- | :-- | :-- |
| Synchronous | None | N/A | No |
| Asynchronous | 2 | Exponential backoff | Yes |
| Stream-based | Until success or data expires | Depends on source | Yes (SQS/SNS) |

**Asynchronous Retry Configuration:**

```bash
# Configure retry behavior
aws lambda put-function-event-invoke-config \
    --function-name my-function \
    --maximum-retry-attempts 1 \
    --maximum-event-age-in-seconds 3600 \
    --destination-config '{
      "OnSuccess": {
        "Destination": "arn:aws:sqs:us-east-1:123456789012:success-queue"
      },
      "OnFailure": {
        "Destination": "arn:aws:sqs:us-east-1:123456789012:dlq"
      }
    }'
```

**Implementing Idempotency:**

```python
# idempotent_lambda.py
import json
import boto3
from datetime import datetime, timedelta

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('IdempotencyStore')

def lambda_handler(event, context):
    """
    Idempotent Lambda function using DynamoDB for deduplication
    """
    
    # Generate idempotency key from event
    idempotency_key = generate_idempotency_key(event)
    
    # Check if already processed
    response = table.get_item(Key={'requestId': idempotency_key})
    
    if 'Item' in response:
        # Already processed - return cached result
        print(f"Request {idempotency_key} already processed")
        return json.loads(response['Item']['result'])
    
    try:
        # Process request
        result = process_request(event)
        
        # Store result with TTL
        ttl = int((datetime.now() + timedelta(hours=24)).timestamp())
        table.put_item(
            Item={
                'requestId': idempotency_key,
                'result': json.dumps(result),
                'processedAt': datetime.now().isoformat(),
                'ttl': ttl
            }
        )
        
        return result
        
    except Exception as e:
        # Don't cache errors
        print(f"Error processing request: {str(e)}")
        raise

def generate_idempotency_key(event):
    """Generate unique key from event"""
    import hashlib
    
    # For API Gateway
    if 'requestContext' in event:
        return event['requestContext']['requestId']
    
    # For S3 events
    if 'Records' in event and event['Records'][0]['eventSource'] == 'aws:s3':
        record = event['Records'][0]
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        etag = record['s3']['object']['eTag']
        return hashlib.sha256(f"{bucket}/{key}/{etag}".encode()).hexdigest()
    
    # Generic fallback
    return hashlib.sha256(json.dumps(event, sort_keys=True).encode()).hexdigest()

def process_request(event):
    """Your business logic here"""
    # Process the request
    return {'status': 'success', 'data': 'processed'}
```

**Circuit Breaker Pattern:**

```python
# circuit_breaker.py
import time
import json
from enum import Enum

class CircuitState(Enum):
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failures detected, blocking requests
    HALF_OPEN = "half_open"  # Testing if service recovered

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60, success_threshold=2):
        self.failure_threshold = failure_threshold
        self.timeout = timeout  # seconds
        self.success_threshold = success_threshold
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection"""
        
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.timeout:
                print("Circuit breaker: Attempting recovery (HALF_OPEN)")
                self.state = CircuitState.HALF_OPEN
            else:
                raise Exception("Circuit breaker is OPEN - service unavailable")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise
    
    def _on_success(self):
        """Handle successful call"""
        if self.state == CircuitState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.success_threshold:
                print("Circuit breaker: Service recovered (CLOSED)")
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                self.success_count = 0
        else:
            self.failure_count = 0
    
    def _on_failure(self):
        """Handle failed call"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            print(f"Circuit breaker: Too many failures (OPEN)")
            self.state = CircuitState.OPEN
            self.success_count = 0

# Usage in Lambda
import boto3

external_api_breaker = CircuitBreaker(failure_threshold=3, timeout=30)

def call_external_api(data):
    """Call external API with circuit breaker"""
    # Your API call here
    import requests
    response = requests.post('https://api.example.com/endpoint', json=data)
    response.raise_for_status()
    return response.json()

def lambda_handler(event, context):
    try:
        result = external_api_breaker.call(call_external_api, event['data'])
        return {'statusCode': 200, 'body': json.dumps(result)}
    except Exception as e:
        return {'statusCode': 503, 'body': json.dumps({'error': str(e)})}
```


### Advanced Observability

**Structured Logging with AWS Lambda Powertools:**

```python
# advanced_logging.py
from aws_lambda_powertools import Logger, Tracer, Metrics
from aws_lambda_powertools.metrics import MetricUnit
from aws_lambda_powertools.utilities.typing import LambdaContext

logger = Logger(service="payment-service")
tracer = Tracer(service="payment-service")
metrics = Metrics(namespace="PaymentService", service="payment-service")

@logger.inject_lambda_context(log_event=True)
@tracer.capture_lambda_handler
@metrics.log_metrics(capture_cold_start_metric=True)
def lambda_handler(event: dict, context: LambdaContext) -> dict:
    """
    Payment processing with comprehensive observability
    """
    
    # Structured logging
    logger.info("Processing payment", extra={
        "payment_id": event.get('paymentId'),
        "amount": event.get('amount'),
        "currency": event.get('currency')
    })
    
    try:
        # Add custom metrics
        metrics.add_metric(
            name="PaymentAttempt",
            unit=MetricUnit.Count,
            value=1
        )
        
        # Process payment with tracing
        result = process_payment(event)
        
        # Log success
        logger.info("Payment successful", extra={
            "payment_id": event.get('paymentId'),
            "transaction_id": result['transactionId']
        })
        
        metrics.add_metric(
            name="PaymentSuccess",
            unit=MetricUnit.Count,
            value=1
        )
        
        metrics.add_metric(
            name="PaymentAmount",
            unit=MetricUnit.None,
            value=event.get('amount', 0)
        )
        
        return {
            'statusCode': 200,
            'body': json.dumps(result)
        }
        
    except Exception as e:
        logger.exception("Payment failed", extra={
            "payment_id": event.get('paymentId'),
            "error": str(e)
        })
        
        metrics.add_metric(
            name="PaymentFailure",
            unit=MetricUnit.Count,
            value=1
        )
        
        raise

@tracer.capture_method
def process_payment(event: dict) -> dict:
    """Process payment with distributed tracing"""
    
    # Annotate trace
    tracer.put_annotation(key="PaymentId", value=event.get('paymentId'))
    tracer.put_metadata(key="PaymentDetails", value={
        "amount": event.get('amount'),
        "currency": event.get('currency')
    })
    
    # Call payment gateway
    result = call_payment_gateway(event)
    
    return result

@tracer.capture_method
def call_payment_gateway(event: dict) -> dict:
    """Call external payment gateway"""
    import requests
    
    response = requests.post(
        'https://gateway.example.com/charge',
        json=event,
        timeout=5
    )
    
    response.raise_for_status()
    return response.json()
```

**CloudWatch Insights Queries:**

```sql
-- Find errors in last hour
fields @timestamp, @message, errorType, errorMessage
| filter @message like /ERROR/
| sort @timestamp desc
| limit 100

-- Calculate p50, p95, p99 latency
filter @type = "REPORT"
| stats avg(@duration), percentile(@duration, 50), percentile(@duration, 95), percentile(@duration, 99) by bin(5m)

-- Memory usage analysis
filter @type = "REPORT"
| stats max(@memorySize / 1000 / 1000) as provisioned_memory_mb,
    min(@maxMemoryUsed / 1000 / 1000) as min_memory_mb,
    avg(@maxMemoryUsed / 1000 / 1000) as avg_memory_mb,
    max(@maxMemoryUsed / 1000 / 1000) as max_memory_mb
| display provisioned_memory_mb, min_memory_mb, avg_memory_mb, max_memory_mb

-- Find cold starts
filter @type = "REPORT"
| fields @timestamp, @duration, @initDuration
| filter ispresent(@initDuration)
| sort @timestamp desc

-- Cost analysis
filter @type = "REPORT"
| stats sum(@billedDuration) / 1000 / 60 / 60 as total_hours,
    avg(@memorySize) / 1024 as avg_memory_gb,
    count(*) as invocation_count
```

**X-Ray Integration:**

```python
# xray_integration.py
from aws_xray_sdk.core import xray_recorder
from aws_xray_sdk.core import patch_all

# Patch libraries for automatic instrumentation
patch_all()

def lambda_handler(event, context):
    """
    Lambda with X-Ray tracing
    """
    
    # Custom subsegment
    with xray_recorder.capture('process_order') as subsegment:
        subsegment.put_annotation('order_id', event['orderId'])
        subsegment.put_metadata('order_details', event)
        
        # Process order
        result = process_order(event)
        
        subsegment.put_metadata('result', result)
    
    return result

def process_order(event):
    """Automatically traced by patch_all()"""
    import boto3
    
    # DynamoDB call (automatically traced)
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('Orders')
    
    table.put_item(Item={
        'orderId': event['orderId'],
        'status': 'processing'
    })
    
    # HTTP call (automatically traced)
    import requests
    response = requests.get('https://api.example.com/inventory')
    
    return {'status': 'success'}
```


### Lambda Performance Optimization

**Memory vs Performance vs Cost:**

```python
# benchmark_memory.py
import time

def benchmark_performance():
    """
    Test different memory allocations:
    
    128 MB: $0.0000000021 per 100ms, slower CPU
    512 MB: $0.0000000083 per 100ms, ~2x CPU
    1024 MB: $0.0000000167 per 100ms, ~4x CPU
    3008 MB: $0.0000000500 per 100ms, ~12x CPU
    
    Sweet spot often: 1024 MB - 2048 MB
    """
    
    start = time.time()
    
    # CPU-intensive operation
    result = sum(i**2 for i in range(1000000))
    
    duration = time.time() - start
    
    print(f"Duration: {duration:.3f}s")
    print(f"Result: {result}")
    
    return duration

def lambda_handler(event, context):
    """
    Test at different memory settings:
    
    128 MB: 2.5s × $0.0000000021 × 25 = $0.000001313
    1024 MB: 0.3s × $0.0000000167 × 3 = $0.000000150
    
    1024 MB is 8.7x cheaper despite higher rate!
    """
    
    duration = benchmark_performance()
    
    return {
        'duration': duration,
        'memory': context.memory_limit_in_mb,
        'remaining_time': context.get_remaining_time_in_millis()
    }
```

**Connection Pooling:**

```python
# connection_pooling.py
import pymysql
import os

# Initialize outside handler (reused across invocations)
connection = None

def get_connection():
    """Reuse database connection"""
    global connection
    
    if connection is None or not connection.open:
        print("Creating new database connection")
        connection = pymysql.connect(
            host=os.environ['DB_HOST'],
            user=os.environ['DB_USER'],
            password=os.environ['DB_PASSWORD'],
            database=os.environ['DB_NAME'],
            connect_timeout=5,
            cursorclass=pymysql.cursors.DictCursor
        )
    else:
        print("Reusing existing connection")
    
    return connection

def lambda_handler(event, context):
    """
    Connection reused across warm invocations
    Cold start: 500ms (connection setup)
    Warm start: 50ms (reuse connection)
    """
    
    conn = get_connection()
    
    try:
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM users WHERE id = %s", (event['userId'],))
            result = cursor.fetchone()
        
        return {
            'statusCode': 200,
            'body': json.dumps(result)
        }
    except Exception as e:
        # Connection might be stale, reset
        connection = None
        raise
```

**Lazy Loading:**

```python
# lazy_loading.py

# Bad - loaded on every cold start even if not needed
import heavy_ml_library
import large_data_processing_lib

def lambda_handler(event, context):
    if event['action'] == 'simple':
        return simple_action()
    else:
        return complex_action()

# Good - lazy import only when needed
def lambda_handler(event, context):
    if event['action'] == 'simple':
        return simple_action()
    else:
        # Only import when needed
        import heavy_ml_library
        import large_data_processing_lib
        return complex_action()

def simple_action():
    """Doesn't need heavy libraries"""
    return {'result': 'simple'}

def complex_action():
    """Uses heavy libraries"""
    # Libraries already imported locally
    return {'result': 'complex'}
```


### Cost Optimization Strategies

**Lambda Compute Savings Plan:**

```
Commit to consistent usage (compute seconds per hour)
Example: Commit to 100 compute-seconds/hour for 1 year

Standard pricing: $0.0000166667 per GB-second
Savings Plan: ~17% discount

Best for: Stable, predictable workloads
```

**Optimize Execution Time:**

```python
# Cost comparison examples

# Inefficient: Multiple separate calls
def process_items_bad(items):
    """
    100 items × 100ms each = 10,000ms total
    Cost: Higher
    """
    results = []
    for item in items:
        result = boto3.client('dynamodb').get_item(
            TableName='Items',
            Key={'id': item}
        )
        results.append(result)
    return results

# Efficient: Batch operations
def process_items_good(items):
    """
    Batch of 100 items = 200ms total
    Cost: 50x lower
    """
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('Items')
    
    # Batch get (25 items per request)
    results = []
    for i in range(0, len(items), 25):
        batch = items[i:i+25]
        response = dynamodb.batch_get_item(
            RequestItems={
                'Items': {
                    'Keys': [{'id': item} for item in batch]
                }
            }
        )
        results.extend(response['Responses']['Items'])
    
    return results
```

**Right-Size Memory:**

```python
# memory_optimizer.py
def analyze_memory_usage():
    """
    Monitor memory usage to right-size
    
    AWS Lambda Power Tuning tool:
    https://github.com/alexcasalboni/aws-lambda-power-tuning
    
    Tests function at different memory settings
    Finds optimal price/performance point
    """
    
    import json
    
    # Use Lambda Power Tuning State Machine
    step_functions = boto3.client('stepfunctions')
    
    execution = step_functions.start_execution(
        stateMachineArn='arn:aws:states:us-east-1:123456789012:stateMachine:powerTuningStateMachine',
        input=json.dumps({
            'lambdaARN': 'arn:aws:lambda:us-east-1:123456789012:function:my-function',
            'powerValues': [128, 256, 512, 1024, 1536, 2048, 3008],
            'num': 100,
            'payload': {},
            'parallelInvocation': True,
            'strategy': 'cost'
        })
    )
    
    return execution['executionArn']
```


## Tips \& Best Practices

### Cold Start Optimization Tips

**Tip 1: Use Provisioned Concurrency for Latency-Sensitive APIs**

```bash
# Enable provisioned concurrency
aws lambda put-provisioned-concurrency-config \
    --function-name api-function \
    --provisioned-concurrent-executions 10 \
    --qualifier prod

# Use Application Auto Scaling
aws application-autoscaling register-scalable-target \
    --service-namespace lambda \
    --resource-id function:api-function:prod \
    --scalable-dimension lambda:function:ProvisionedConcurrentExecutions \
    --min-capacity 5 \
    --max-capacity 50

aws application-autoscaling put-scaling-policy \
    --service-namespace lambda \
    --resource-id function:api-function:prod \
    --scalable-dimension lambda:function:ProvisionedConcurrentExecutions \
    --policy-name target-tracking \
    --policy-type TargetTrackingScaling \
    --target-tracking-scaling-policy-configuration '{
      "TargetValue": 0.70,
      "PredefinedMetricSpecification": {
        "PredefinedMetricType": "LambdaProvisionedConcurrencyUtilization"
      }
    }'
```

**Tip 2: Use Lambda SnapStart for Java**

```bash
# Enable SnapStart for Java function
aws lambda update-function-configuration \
    --function-name java-function \
    --snap-start ApplyOn=PublishedVersions

# Publish version
aws lambda publish-version \
    --function-name java-function

# Update alias to new version
aws lambda update-alias \
    --function-name java-function \
    --name prod \
    --function-version 2
```

**Tip 3: Minimize Deployment Package Size**

```bash
# Use Lambda layers for dependencies
# Create layer
cd python-layer
mkdir python
pip install requests -t python/
zip -r layer.zip python/

aws lambda publish-layer-version \
    --layer-name requests-layer \
    --zip-file fileb://layer.zip \
    --compatible-runtimes python3.11

# Function only contains business logic (small package)
# Attach layer
aws lambda update-function-configuration \
    --function-name my-function \
    --layers arn:aws:lambda:us-east-1:123456789012:layer:requests-layer:1
```

**Tip 4: Keep Functions Warm with EventBridge**

```bash
# For critical functions, ping every 5 minutes
aws events put-rule \
    --name keep-lambda-warm \
    --schedule-expression "rate(5 minutes)" \
    --state ENABLED

aws events put-targets \
    --rule keep-lambda-warm \
    --targets "Id"="1","Arn"="arn:aws:lambda:us-east-1:123456789012:function:critical-api","Input"='{"warmup":true}'

# In Lambda, detect warmup
def lambda_handler(event, context):
    if event.get('warmup'):
        return {'status': 'warm'}
    
    # Normal processing
    return process_request(event)
```


### Memory Configuration Tips

**Tip 5: Start with 1024 MB for Most Functions**

Sweet spot for price/performance:

- Below 1024 MB: Slower CPU, may increase duration cost
- 1024 MB: Good CPU, reasonable cost
- Above 2048 MB: Diminishing returns unless CPU-bound

**Tip 6: Monitor Memory Usage**

```python
# Log memory usage
import os
import psutil

def lambda_handler(event, context):
    # Get memory stats
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    
    print(f"Memory allocated: {context.memory_limit_in_mb} MB")
    print(f"Memory used: {memory_info.rss / 1024 / 1024:.2f} MB")
    print(f"Memory available: {context.memory_limit_in_mb - (memory_info.rss / 1024 / 1024):.2f} MB")
    
    # Your code here
    result = process_data(event)
    
    # Log final memory usage
    memory_info_after = process.memory_info()
    print(f"Memory after processing: {memory_info_after.rss / 1024 / 1024:.2f} MB")
    
    return result
```


### VPC Lambda Tips

**Tip 7: Use VPC Endpoints for AWS Services**

```bash
# Instead of NAT Gateway ($32/month + data)
# Use VPC endpoints (free for S3/DynamoDB, small cost for others)

# Create S3 endpoint (gateway, free)
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --service-name com.amazonaws.us-east-1.s3 \
    --route-table-ids rtb-12345678

# Create Secrets Manager endpoint (interface, ~$7/month)
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --vpc-endpoint-type Interface \
    --service-name com.amazonaws.us-east-1.secretsmanager \
    --subnet-ids subnet-12345678 subnet-87654321 \
    --security-group-ids sg-12345678
```

**Tip 8: Place Lambda and RDS in Same AZ**

```bash
# Subnet strategy
# Lambda subnets: us-east-1a, us-east-1b
# RDS primary: us-east-1a
# Most invocations will be in same AZ (lower latency)
```


### Error Handling Tips

**Tip 9: Implement Dead Letter Queues**

```bash
# Configure DLQ for asynchronous functions
aws lambda update-function-configuration \
    --function-name my-function \
    --dead-letter-config TargetArn=arn:aws:sqs:us-east-1:123456789012:lambda-dlq

# Process DLQ messages
# Create separate Lambda to process failures
```

**Tip 10: Use Destinations Instead of DLQ**

```bash
# Destinations provide more information than DLQ
aws lambda put-function-event-invoke-config \
    --function-name my-function \
    --destination-config '{
      "OnSuccess": {
        "Destination": "arn:aws:sns:us-east-1:123456789012:success-topic"
      },
      "OnFailure": {
        "Destination": "arn:aws:sqs:us-east-1:123456789012:failure-queue"
      }
    }'
```


### Security Tips

**Tip 11: Use Parameter Store for Configuration**

```python
# Cached parameter retrieval
import boto3
import os
from functools import lru_cache

ssm = boto3.client('ssm')

@lru_cache(maxsize=128)
def get_parameter(name):
    """Cache parameter for Lambda lifetime"""
    response = ssm.get_parameter(
        Name=name,
        WithDecryption=True
    )
    return response['Parameter']['Value']

def lambda_handler(event, context):
    # Retrieved once per container lifetime
    api_key = get_parameter('/myapp/api-key')
    db_password = get_parameter('/myapp/db-password')
    
    # Use parameters
    return process_with_credentials(event, api_key, db_password)
```

**Tip 12: Least Privilege IAM Roles**

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::my-specific-bucket/uploads/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:PutItem",
        "dynamodb:GetItem"
      ],
      "Resource": "arn:aws:dynamodb:us-east-1:123456789012:table/MyTable"
    }
  ]
}
```


### Monitoring Tips

**Tip 13: Use Custom Metrics**

```python
import boto3

cloudwatch = boto3.client('cloudwatch')

def lambda_handler(event, context):
    # Track business metrics
    cloudwatch.put_metric_data(
        Namespace='MyApp/Orders',
        MetricData=[
            {
                'MetricName': 'OrdersProcessed',
                'Value': 1,
                'Unit': 'Count'
            },
            {
                'MetricName': 'OrderAmount',
                'Value': event['amount'],
                'Unit': 'None'
            }
        ]
    )
    
    return process_order(event)
```

**Tip 14: Set Up Composite Alarms**

```bash
# Alarm on multiple conditions
aws cloudwatch put-composite-alarm \
    --alarm-name critical-lambda-issues \
    --alarm-rule "ALARM(high-error-rate) OR ALARM(high-throttles) OR ALARM(low-success-rate)" \
    --actions-enabled \
    --alarm-actions arn:aws:sns:us-east-1:123456789012:critical-alerts
```


## Pitfalls \& Remedies

### Pitfall 1: Timeout Issues

**Problem:** Lambda function times out before completing work.

**Why It Happens:**

- Default 3-second timeout too short
- Long-running operations (API calls, database queries)
- Not handling slow dependencies
- Processing large datasets

**Impact:**

- Failed requests
- Partial data processing
- Wasted costs (billed for timeout duration)
- Retry storms

**Remedy:**

**Step 1: Identify Timeout Causes**

```python
# timeout_debugging.py
import time
import json

def lambda_handler(event, context):
    """
    Log operation durations to identify bottlenecks
    """
    
    start_time = time.time()
    
    # Log remaining time
    print(f"Timeout configured: {context.get_remaining_time_in_millis() / 1000}s")
    
    # Operation 1
    op1_start = time.time()
    result1 = database_query()
    print(f"Database query took: {time.time() - op1_start:.2f}s")
    
    # Operation 2
    op2_start = time.time()
    result2 = external_api_call()
    print(f"API call took: {time.time() - op2_start:.2f}s")
    
    # Operation 3
    op3_start = time.time()
    result3 = data_processing(result1, result2)
    print(f"Processing took: {time.time() - op3_start:.2f}s")
    
    total_time = time.time() - start_time
    remaining = context.get_remaining_time_in_millis() / 1000
    
    print(f"Total execution time: {total_time:.2f}s")
    print(f"Remaining time: {remaining:.2f}s")
    
    if remaining < 1:
        print("WARNING: Close to timeout!")
    
    return {'statusCode': 200}
```

**Step 2: Increase Timeout Appropriately**

```bash
# Analyze CloudWatch Logs to find max duration
# Set timeout = max duration × 1.5 (buffer)

# Update timeout
aws lambda update-function-configuration \
    --function-name my-function \
    --timeout 30  # seconds

# For long-running tasks, use Step Functions instead
```

**Step 3: Implement Timeout Handling**

```python
# graceful_timeout.py
import signal

class TimeoutError(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutError("Function about to timeout")

def lambda_handler(event, context):
    """
    Handle approaching timeout gracefully
    """
    
    # Set alarm for 80% of remaining time
    remaining_ms = context.get_remaining_time_in_millis()
    alarm_time = int(remaining_ms * 0.8 / 1000)
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(alarm_time)
    
    try:
        # Process items
        results = []
        for item in event['items']:
            result = process_item(item)
            results.append(result)
        
        return {
            'statusCode': 200,
            'processed': len(results),
            'results': results
        }
        
    except TimeoutError:
        # Save partial results
        print(f"Timeout approaching, processed {len(results)} items")
        
        # Save state to continue later
        save_checkpoint(results, event['items'][len(results):])
        
        return {
            'statusCode': 206,  # Partial Content
            'processed': len(results),
            'remaining': len(event['items']) - len(results)
        }
    finally:
        signal.alarm(0)  # Cancel alarm
```

**Step 4: Use Step Functions for Long Workflows**

```json
{
  "Comment": "Long-running workflow with multiple Lambda functions",
  "StartAt": "ProcessBatch1",
  "States": {
    "ProcessBatch1": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:process-batch",
      "Next": "ProcessBatch2",
      "Retry": [{
        "ErrorEquals": ["States.TaskFailed"],
        "IntervalSeconds": 2,
        "MaxAttempts": 3,
        "BackoffRate": 2
      }]
    },
    "ProcessBatch2": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:process-batch",
      "Next": "Finalize"
    },
    "Finalize": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:finalize",
      "End": true
    }
  }
}
```

**Prevention:**

- Set timeout based on actual duration + buffer
- Monitor duration metrics
- Implement graceful timeout handling
- Use Step Functions for workflows > 15 minutes
- Add circuit breakers for external dependencies

***

### Pitfall 2: Concurrency Throttling

**Problem:** Lambda throttled due to concurrency limits, causing 429 errors.

**Why It Happens:**

- Account limit (1,000 default) shared across all functions
- Traffic spikes exceed capacity
- One function consuming all concurrency
- Not using reserved concurrency

**Impact:**

- Failed requests (synchronous invocations)
- Processing delays (asynchronous invocations)
- Poor user experience
- Cascading failures

**Remedy:**

**Step 1: Monitor Concurrency Usage**

```bash
# CloudWatch metric: ConcurrentExecutions
aws cloudwatch get-metric-statistics \
    --namespace AWS/Lambda \
    --metric-name ConcurrentExecutions \
    --dimensions Name=FunctionName,Value=my-function \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 60 \
    --statistics Maximum,Average

# Check for throttles
aws cloudwatch get-metric-statistics \
    --namespace AWS/Lambda \
    --metric-name Throttles \
    --dimensions Name=FunctionName,Value=my-function \
    --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 60 \
    --statistics Sum
```

**Step 2: Request Limit Increase**

```bash
# Request account concurrency increase via AWS Support
# Or through Service Quotas console

aws service-quotas request-service-quota-increase \
    --service-code lambda \
    --quota-code L-B99A9384 \
    --desired-value 5000

# Check current limit
aws lambda get-account-settings
```

**Step 3: Set Reserved Concurrency**

```bash
# Protect critical functions
aws lambda put-function-concurrency \
    --function-name critical-api \
    --reserved-concurrent-executions 500

# Limit non-critical functions
aws lambda put-function-concurrency \
    --function-name batch-processor \
    --reserved-concurrent-executions 100
```

**Step 4: Implement Backpressure**

```python
# sqs_backpressure.py
def lambda_handler(event, context):
    """
    SQS with controlled batch size prevents overwhelming Lambda
    """
    
    # Process records with error handling
    successful = []
    failed = []
    
    for record in event['Records']:
        try:
            result = process_record(record)
            successful.append(result)
        except Exception as e:
            print(f"Failed to process record: {e}")
            failed.append({
                'itemIdentifier': record['messageId']
            })
    
    # Return batch item failures (partial batch failure)
    # Failed messages return to queue
    return {
        'batchItemFailures': failed
    }

# Configure event source mapping with smaller batch
# aws lambda update-event-source-mapping \
#     --uuid <mapping-id> \
#     --batch-size 5 \
#     --maximum-batching-window-in-seconds 10
```

**Step 5: Use SQS as Buffer**

```
High Traffic → SQS Queue → Lambda (controlled concurrency)
                ↓
         Dead Letter Queue (failed messages)
```

```bash
# Configure maximum concurrency for SQS trigger
aws lambda update-event-source-mapping \
    --uuid mapping-uuid \
    --maximum-concurrency 10  # Limits concurrent Lambda invocations
```

**Prevention:**

- Monitor concurrency metrics
- Set reserved concurrency for critical functions
- Use SQS for buffering high-volume events
- Request limit increases proactively
- Implement exponential backoff in clients

***

### Pitfall 3: VPC Lambda Performance Issues

**Problem:** VPC Lambda functions have slow cold starts and high latency.

**Why It Happens:**

- Old issue: ENI creation took 10-60 seconds
- Current: Still adds ~1 second latency
- Incorrect subnet/security group configuration
- Missing VPC endpoints (traffic goes through NAT)

**Impact:**

- Slow response times
- Poor user experience
- Higher costs (longer duration)
- Connectivity issues

**Remedy:**

**Step 1: Use VPC Endpoints**

```bash
# Create VPC endpoints for AWS services
# Avoids NAT Gateway ($32/month + data charges)

# S3 Gateway Endpoint (free)
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --service-name com.amazonaws.us-east-1.s3 \
    --route-table-ids rtb-12345678 rtb-87654321

# DynamoDB Gateway Endpoint (free)
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --service-name com.amazonaws.us-east-1.dynamodb \
    --route-table-ids rtb-12345678 rtb-87654321

# Secrets Manager Interface Endpoint (~$7/month)
aws ec2 create-vpc-endpoint \
    --vpc-id vpc-12345678 \
    --vpc-endpoint-type Interface \
    --service-name com.amazonaws.us-east-1.secretsmanager \
    --subnet-ids subnet-1 subnet-2 \
    --security-group-ids sg-12345678
```

**Step 2: Optimize Security Groups**

```bash
# Allow Lambda to access RDS
# Lambda security group: sg-lambda
# RDS security group: sg-rds

# Add inbound rule to RDS security group
aws ec2 authorize-security-group-ingress \
    --group-id sg-rds \
    --protocol tcp \
    --port 5432 \
    --source-group sg-lambda
```

**Step 3: Avoid VPC If Not Needed**

```python
# Instead of VPC Lambda accessing public API:
# Lambda (VPC) → NAT Gateway → Internet → API

# Better: Non-VPC Lambda
# Lambda (no VPC) → Internet → API

# Use VPC only when accessing private resources:
# - RDS databases
# - ElastiCache
# - Internal APIs
# - Resources without public endpoints
```

**Step 4: Use RDS Proxy**

```bash
# RDS Proxy manages connection pooling
# Reduces cold start impact

aws rds create-db-proxy \
    --db-proxy-name myapp-proxy \
    --engine-family POSTGRESQL \
    --auth '[{
      "AuthScheme": "SECRETS",
      "SecretArn": "arn:aws:secretsmanager:us-east-1:123456789012:secret:db-secret",
      "IAMAuth": "DISABLED"
    }]' \
    --role-arn arn:aws:iam::123456789012:role/RDSProxyRole \
    --vpc-subnet-ids subnet-1 subnet-2 subnet-3
```

```python
# Connect to RDS Proxy instead of RDS directly
import pymysql

connection = pymysql.connect(
    host='myapp-proxy.proxy-xxx.us-east-1.rds.amazonaws.com',  # Proxy endpoint
    user='admin',
    password=password,
    database='mydb'
)
```

**Prevention:**

- Only use VPC when necessary
- Implement VPC endpoints for AWS services
- Use RDS Proxy for database connections
- Monitor ENI creation metrics
- Test VPC Lambda performance before production

***

## Chapter Summary

AWS Lambda and serverless computing represent a fundamental shift in how applications are built and deployed. By eliminating server management and providing automatic scaling with pay-per-use pricing, Lambda enables developers to focus on business logic rather than infrastructure. Understanding Lambda's execution model, cold starts, concurrency, VPC configuration, and cost optimization is essential for building production-grade serverless applications.

**Key Takeaways:**

- **Lambda execution model:** Understand cold starts vs warm starts, initialization phases, and execution environment reuse
- **Memory allocation matters:** More memory = more CPU = faster execution, often resulting in lower costs despite higher per-second rates
- **Concurrency management:** Monitor usage, set reserved concurrency for critical functions, use provisioned concurrency for latency-sensitive workloads
- **VPC considerations:** Only use VPC when necessary, implement VPC endpoints, use RDS Proxy for databases
- **Error handling:** Implement idempotency, use DLQs/destinations, retry logic, circuit breakers
- **Cost optimization:** Right-size memory, optimize execution time, use batch operations, leverage free tier
- **Observability:** Structured logging, X-Ray tracing, custom metrics, CloudWatch Insights queries

Understanding Lambda deeply, from cold start optimization to production error handling patterns, enables you to build scalable, cost-effective, event-driven applications that leverage the full power of serverless computing.

In Chapter 8, we'll explore AWS storage services (S3, EBS, EFS), which often serve as triggers and data stores for serverless applications.

## Review Questions

1. **What is the maximum Lambda execution time?**
a) 5 minutes
b) 10 minutes
c) 15 minutes
d) 30 minutes

**Answer: C** - Maximum Lambda timeout is 900 seconds (15 minutes).

2. **Which invocation type does API Gateway use?**
a) Asynchronous
b) Synchronous
c) Poll-based
d) Event-driven

**Answer: B** - API Gateway uses synchronous invocation (waits for response).

3. **What is the default Lambda concurrency limit per region?**
a) 100
b) 500
c) 1,000
d) 10,000

**Answer: C** - Default account-level limit is 1,000 concurrent executions (soft limit).

4. **Which runtime typically has the fastest cold start?**
a) Java
b) Python
c) .NET
d) Go

**Answer: D** - Go has fastest cold starts (~100-150ms) due to compiled nature.

5. **What does provisioned concurrency eliminate?**
a) Costs
b) Cold starts
c) Errors
d) Timeouts

**Answer: B** - Provisioned concurrency pre-initializes environments, eliminating cold starts.

6. **Maximum deployment package size (with layers)?**
a) 50 MB
b) 100 MB
c) 250 MB
d) 500 MB

**Answer: C** - Total unzipped size (function + layers) must be ≤ 250 MB.

7. **Which service should you use for Lambda workflows > 15 minutes?**
a) Increase timeout
b) AWS Step Functions
c) ECS
d) Not possible

**Answer: B** - Step Functions orchestrates long-running workflows using multiple Lambda functions.

8. **What happens on Lambda throttle with synchronous invocation?**
a) Automatic retry
b) Sent to DLQ
c) Returns 429 error
d) Queued for later

**Answer: C** - Synchronous invocations return 429 TooManyRequestsException immediately.

9. **Lambda SnapStart is available for which runtime?**
a) Python
b) Node.js
c) Java
d) All runtimes

**Answer: C** - SnapStart currently only supports Java 11+ runtimes.

10. **Which is true about VPC Lambda?**
a) Always faster than non-VPC
b) Adds ~1 second cold start latency
c) Free data transfer
d) Required for S3 access

**Answer: B** - VPC Lambda adds approximately 1 second to cold start time.

11. **Maximum Lambda memory allocation?**
a) 3,008 MB
b) 5,120 MB
c) 10,240 MB
d) Unlimited

**Answer: C** - Maximum memory is 10,240 MB (10 GB).

12. **Which invocation type supports DLQ?**
a) Synchronous only
b) Asynchronous only
c) Poll-based only
d) All types

**Answer: B** - Dead Letter Queues are supported for asynchronous invocations.

13. **Lambda free tier includes:**
a) 100,000 requests/month
b) 500,000 requests/month
c) 1 million requests/month
d) 10 million requests/month

**Answer: C** - Free tier includes 1M requests + 400,000 GB-seconds compute time monthly.

14. **At what memory does Lambda get 1 full vCPU?**
a) 1,024 MB
b) 1,536 MB
c) 1,769 MB
d) 2,048 MB

**Answer: C** - At 1,769 MB, Lambda gets approximately 1 full vCPU.

15. **Which feature reduces Java cold starts by 10x?**
a) Provisioned concurrency
b) Lambda SnapStart
c) Larger memory
d) Lambda layers

**Answer: B** - Lambda SnapStart reduces Java cold starts from seconds to milliseconds.

***
